{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "    \n",
        "    METIN EREN DURUCAN - ZEYNEP CINDEMIR - KEREM AY (GROUP 17)\n",
        "\n",
        "    YAP470 PROJECT - Minimum Bisection Problem\n",
        "    This script is used to run the inference on the test graphs.\n",
        "\n",
        "    Usage:\n",
        "        python inference.ipynb\n",
        "\n",
        "    Output:\n",
        "        A prediction of the input graph's minimum bisection.\n",
        "        \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h6H0O6r9apQa"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from joblib import load\n",
        "import pickle\n",
        "from node2vec import Node2Vec\n",
        "from gensim.models import Word2Vec\n",
        "from networkx.algorithms import community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oN0_zKPhar4Q"
      },
      "outputs": [],
      "source": [
        "def create_Big_Graphs():\n",
        "  num_nodes = 2000\n",
        "  BigList_2000 =[]\n",
        "  random_complete = nx.complete_graph(num_nodes)\n",
        "  for i in range(num_nodes):\n",
        "    for j in range(i + 1, num_nodes):\n",
        "      if random.random() < 0.5:\n",
        "        random_complete.remove_edge(i, j)\n",
        "  BigList_2000.append(random_complete)\n",
        "  #-------------------------------------------------\n",
        "  random_multigraph = nx.MultiGraph()\n",
        "  for i in range(num_nodes):\n",
        "      random_multigraph.add_node(i)\n",
        "  for i in range(num_nodes):\n",
        "      for j in range(i + 1, num_nodes):\n",
        "          if random.random() < 0.5:\n",
        "              random_multigraph.add_edge(i, j)\n",
        "  BigList_2000.append(random_multigraph)\n",
        "  #-------------------------------------------------\n",
        "  pseudograph = nx.MultiGraph()\n",
        "  pseudograph.add_nodes_from(range(num_nodes))\n",
        "  for node in pseudograph.nodes():\n",
        "      pseudograph.add_edge(node, node)\n",
        "      random_nodes = random.sample(list(pseudograph.nodes()), k=3)\n",
        "      pseudograph.add_edges_from([(node, random_node) for random_node in random_nodes])\n",
        "  BigList_2000.append(pseudograph)\n",
        "  #-------------------------------------------------\n",
        "  planar_graph = nx.random_geometric_graph(num_nodes, radius=0.2)\n",
        "  while not nx.is_connected(planar_graph):\n",
        "      planar_graph = nx.random_geometric_graph(num_nodes, radius=0.2)\n",
        "  BigList_2000.append(planar_graph)\n",
        "  #-------------------------------------------------\n",
        "  def random_hamiltonian_graph(n):\n",
        "      graph = nx.random_regular_graph(2, n)\n",
        "      for i in range(n):\n",
        "          for j in range(i + 1, n):\n",
        "              if random.random() < 0.5 and not graph.has_edge(i, j):\n",
        "                  graph.add_edge(i, j)\n",
        "      return graph\n",
        "  random_hamiltonian_graph = random_hamiltonian_graph(num_nodes)\n",
        "  BigList_2000.append(random_hamiltonian_graph)\n",
        "  return BigList_2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dut1HwJcazIf"
      },
      "outputs": [],
      "source": [
        "def create_main_graphs(num_nodes):\n",
        "  main_list =[]\n",
        "  random_regular_3 = nx.random_regular_graph(3, num_nodes)\n",
        "  random_regular_20 = nx.random_regular_graph(20, num_nodes)\n",
        "  main_list.append(random_regular_3)\n",
        "  main_list.append(random_regular_20)\n",
        "  #-------------------------------------------------\n",
        "  # Create a random connected graph by generating a random spanning tree\n",
        "  random_connected_tree = nx.random_tree(num_nodes)\n",
        "  # Add additional edges to maintain connectivity\n",
        "  while not nx.is_connected(random_connected_tree):\n",
        "      node1 = random.choice(list(random_connected_tree.nodes()))\n",
        "      node2 = random.choice(list(random_connected_tree.nodes()))\n",
        "      if node1 != node2 and not random_connected_tree.has_edge(node1, node2):\n",
        "          random_connected_tree.add_edge(node1, node2)\n",
        "  main_list.append(random_connected_tree)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_cycle_graph(num_nodes):\n",
        "      if num_nodes < 3:\n",
        "          raise ValueError(\"Number of nodes must be at least 3 for a cycle.\")\n",
        "      cycle_graph = nx.cycle_graph(num_nodes)\n",
        "      # Connect the cycle to form a connected cycle graph\n",
        "      connected_cycle_graph = nx.connected_watts_strogatz_graph(num_nodes, 2, 0.1)\n",
        "      return connected_cycle_graph\n",
        "  random_cycle_graph = generate_random_connected_cycle_graph(num_nodes)\n",
        "  main_list.append(random_cycle_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_barabasi_albert_graph(num_nodes, m):\n",
        "      if num_nodes <= m:\n",
        "          raise ValueError(\"Number of nodes must be greater than m for a BarabÃ¡si-Albert graph.\")\n",
        "      ba_graph = nx.barabasi_albert_graph(num_nodes, m)\n",
        "      while not nx.is_connected(ba_graph):\n",
        "          # Add edges to connect the graph\n",
        "          non_edges = list(nx.non_edges(ba_graph))\n",
        "          edge_to_add = non_edges[0]\n",
        "          ba_graph.add_edge(*edge_to_add)\n",
        "      return ba_graph\n",
        "  m_parameter = 2\n",
        "  random_connected_ba_graph = generate_random_connected_barabasi_albert_graph(num_nodes, m_parameter)\n",
        "  main_list.append(random_connected_ba_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_erdos_renyi_graph(num_nodes, probability):\n",
        "      er_graph = nx.erdos_renyi_graph(num_nodes, probability)\n",
        "      while not nx.is_connected(er_graph):\n",
        "          # Add edges to connect the graph\n",
        "          non_edges = list(nx.non_edges(er_graph))\n",
        "          edge_to_add = non_edges[0]\n",
        "          er_graph.add_edge(*edge_to_add)\n",
        "      return er_graph\n",
        "  edge_probability = 0.1  # Adjust as needed\n",
        "  random_connected_er_graph = generate_random_connected_erdos_renyi_graph(num_nodes, edge_probability)\n",
        "  main_list.append(random_connected_er_graph)\n",
        "  #-------------------------------------------------\n",
        "  k = 2  # Each node is connected to k nearest neighbors\n",
        "  p = 0.3  # Probability of rewiring each edge\n",
        "  random_graph_ws = nx.watts_strogatz_graph(num_nodes, k, p)\n",
        "  main_list.append(random_graph_ws)\n",
        "  #-------------------------------------------------\n",
        "  k = 10  # Each node is connected to k nearest neighbors\n",
        "  p = 0.3  # Probability of rewiring each edge\n",
        "  random_graph_ws = nx.watts_strogatz_graph(num_nodes, k, p)\n",
        "  main_list.append(random_graph_ws)\n",
        "  #-------------------------------------------------\n",
        "\n",
        "  def generate_connected_random_geometric_graph(num_nodes, radius):\n",
        "      random_geo_graph = nx.random_geometric_graph(num_nodes, radius)\n",
        "      while not nx.is_connected(random_geo_graph):\n",
        "          # Connect the graph by adding edges\n",
        "          non_edges = list(nx.non_edges(random_geo_graph))\n",
        "          random_edge = random.choice(non_edges)\n",
        "          random_geo_graph.add_edge(*random_edge)\n",
        "      return random_geo_graph\n",
        "  radius = 0.1  # Adjust as needed\n",
        "  connected_random_geo_graph = generate_connected_random_geometric_graph(num_nodes, radius)\n",
        "  main_list.append(connected_random_geo_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_connected_random_internet_graph(num_nodes, k, p):\n",
        "      internet_graph = nx.random_internet_as_graph(num_nodes)\n",
        "      while not nx.is_connected(internet_graph):\n",
        "          non_edges = list(nx.non_edges(internet_graph))\n",
        "          random_edge = non_edges[0]\n",
        "          internet_graph.add_edge(*random_edge)\n",
        "      undirected_internet_graph = internet_graph.to_undirected()\n",
        "      connected_random_internet_graph = nx.connected_watts_strogatz_graph(num_nodes, k, p)\n",
        "      return connected_random_internet_graph\n",
        "  k_parameter = 5\n",
        "  p_parameter = 0.5\n",
        "  connected_random_internet_graph = generate_connected_random_internet_graph(num_nodes, k_parameter, p_parameter)\n",
        "  main_list.append(connected_random_internet_graph)\n",
        "  #-------------------------------------------------\n",
        "  return main_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88tHVQnBfOCW",
        "outputId": "9e9b08e7-e91a-4268-9e1a-8175c1070e9a"
      },
      "outputs": [],
      "source": [
        "BigGraphs = create_Big_Graphs()\n",
        "main_list = create_main_graphs(5000)\n",
        "main_list2 = create_main_graphs(8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total dimensions for BigGraphs: 10000\n",
            "Total dimensions for main_list: 50000\n",
            "Total dimensions for main_list2: 80000\n"
          ]
        }
      ],
      "source": [
        "def total_dimensions(graphs):\n",
        "    return sum(len(graph.nodes()) for graph in graphs)\n",
        "\n",
        "# Calculate total dimensions for each list of graphs\n",
        "total_dims_BigGraphs = total_dimensions(BigGraphs)\n",
        "total_dims_main_list = total_dimensions(main_list)\n",
        "total_dims_main_list2 = total_dimensions(main_list2)\n",
        "\n",
        "print(\"Total dimensions for BigGraphs: {}\".format(total_dims_BigGraphs))\n",
        "print(\"Total dimensions for main_list: {}\".format(total_dims_main_list))\n",
        "print(\"Total dimensions for main_list2: {}\".format(total_dims_main_list2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uZC4_6jAjKJ7"
      },
      "outputs": [],
      "source": [
        "# GCN yayÄ±lÄ±m fonksiyonu.\n",
        "def gcn_propagate(adj_matrix, node_embeddings):\n",
        "    # Laplacian Normalization\n",
        "    degrees = adj_matrix.sum(axis=1)\n",
        "    degree_matrix = np.diag(degrees)\n",
        "    laplacian = degree_matrix - adj_matrix\n",
        "    norm_laplacian = np.linalg.pinv(degree_matrix) @ laplacian\n",
        "    return np.dot(norm_laplacian, node_embeddings)\n",
        "\n",
        "# GCN ile gÃ¶mme vektÃ¶rleri oluÅturur.\n",
        "def generate_embeddings(graphs, target_dim=47616, num_iterations=10):\n",
        "    embeddings = []\n",
        "    for graph in graphs:\n",
        "        adj_matrix = nx.to_numpy_array(graph)\n",
        "        initial_dim = adj_matrix.shape[0]\n",
        "        node_embeddings = np.random.randn(initial_dim, initial_dim)\n",
        "\n",
        "        for _ in range(num_iterations):\n",
        "            node_embeddings = gcn_propagate(adj_matrix, node_embeddings)\n",
        "\n",
        "        graph_embedding = np.mean(node_embeddings, axis=0)\n",
        "        padding_length = max(0, target_dim - graph_embedding.shape[0])\n",
        "        embeddings.append(np.pad(graph_embedding, (0, padding_length), 'constant'))\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "# Ãnceden eÄitilmiÅ bir sÄ±nÄ±flandÄ±rÄ±cÄ± modeli yÃ¼kler.\n",
        "try:\n",
        "    with open('classifier.pkl', 'rb') as file:\n",
        "        loaded_model = pickle.load(file)\n",
        "except FileNotFoundError:\n",
        "    print(\"Model dosyasÄ± bulunamadÄ±.\")\n",
        "    loaded_model = None\n",
        "except Exception as e:\n",
        "    print(f\"Model yÃ¼klenirken bir hata oluÅtu: {e}\")\n",
        "    loaded_model = None\n",
        "\n",
        "# SayaÃ§ tut eÄer 30 dakikayÄ± geÃ§erse timeout ver.\n",
        "import time\n",
        "if loaded_model:\n",
        "    for graphs, name in [(BigGraphs, \"BigGraphs\"), (main_list, \"main_list\"), (main_list2, \"main_list2\")]:\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            embeddings = generate_embeddings(graphs)\n",
        "            elapsed_time = time.time() - start_time\n",
        "\n",
        "            print(f\"Elapsed time: {elapsed_time} seconds\\n\")\n",
        "\n",
        "            if elapsed_time > 1800:\n",
        "                print(\"Timeout!\")\n",
        "\n",
        "            # Tahmin olasÄ±lÄ±klarÄ±nÄ± hesapla\n",
        "            probabilities = loaded_model.predict_proba(embeddings)\n",
        "            # Her tahmin iÃ§in yÃ¼zdelik deÄerleri hesapla\n",
        "            percentage_predictions = np.round(probabilities * 100, 2)  # YÃ¼zdelik deÄerleri yuvarla\n",
        "            print(f\"==== {name} ==== \\nPercentage of predictions: \\n{percentage_predictions}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"{name} iÃ§in tahmin yapÄ±lÄ±rken hata oluÅtu: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
