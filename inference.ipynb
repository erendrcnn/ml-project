{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "    \n",
        "    METIN EREN DURUCAN - ZEYNEP CINDEMIR - KEREM AY (GROUP 17)\n",
        "\n",
        "    YAP470 PROJECT - Minimum Bisection Problem\n",
        "    This script is used to run the inference on the test graphs.\n",
        "\n",
        "    Usage:\n",
        "        python inference.ipynb\n",
        "\n",
        "    Output:\n",
        "        A prediction of the input graph's minimum bisection.\n",
        "        \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h6H0O6r9apQa"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from joblib import load\n",
        "import pickle\n",
        "from node2vec import Node2Vec\n",
        "from gensim.models import Word2Vec\n",
        "from networkx.algorithms import community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oN0_zKPhar4Q"
      },
      "outputs": [],
      "source": [
        "def create_Big_Graphs():\n",
        "  num_nodes = 2000\n",
        "  BigList_2000 =[]\n",
        "  random_complete = nx.complete_graph(num_nodes)\n",
        "  for i in range(num_nodes):\n",
        "    for j in range(i + 1, num_nodes):\n",
        "      if random.random() < 0.5:\n",
        "        random_complete.remove_edge(i, j)\n",
        "  BigList_2000.append(random_complete)\n",
        "  #-------------------------------------------------\n",
        "  random_multigraph = nx.MultiGraph()\n",
        "  for i in range(num_nodes):\n",
        "      random_multigraph.add_node(i)\n",
        "  for i in range(num_nodes):\n",
        "      for j in range(i + 1, num_nodes):\n",
        "          if random.random() < 0.5:\n",
        "              random_multigraph.add_edge(i, j)\n",
        "  BigList_2000.append(random_multigraph)\n",
        "  #-------------------------------------------------\n",
        "  pseudograph = nx.MultiGraph()\n",
        "  pseudograph.add_nodes_from(range(num_nodes))\n",
        "  for node in pseudograph.nodes():\n",
        "      pseudograph.add_edge(node, node)\n",
        "      random_nodes = random.sample(list(pseudograph.nodes()), k=3)\n",
        "      pseudograph.add_edges_from([(node, random_node) for random_node in random_nodes])\n",
        "  BigList_2000.append(pseudograph)\n",
        "  #-------------------------------------------------\n",
        "  planar_graph = nx.random_geometric_graph(num_nodes, radius=0.2)\n",
        "  while not nx.is_connected(planar_graph):\n",
        "      planar_graph = nx.random_geometric_graph(num_nodes, radius=0.2)\n",
        "  BigList_2000.append(planar_graph)\n",
        "  #-------------------------------------------------\n",
        "  def random_hamiltonian_graph(n):\n",
        "      graph = nx.random_regular_graph(2, n)\n",
        "      for i in range(n):\n",
        "          for j in range(i + 1, n):\n",
        "              if random.random() < 0.5 and not graph.has_edge(i, j):\n",
        "                  graph.add_edge(i, j)\n",
        "      return graph\n",
        "  random_hamiltonian_graph = random_hamiltonian_graph(num_nodes)\n",
        "  BigList_2000.append(random_hamiltonian_graph)\n",
        "  return BigList_2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dut1HwJcazIf"
      },
      "outputs": [],
      "source": [
        "def create_main_graphs(num_nodes):\n",
        "  main_list =[]\n",
        "  random_regular_3 = nx.random_regular_graph(3, num_nodes)\n",
        "  random_regular_20 = nx.random_regular_graph(20, num_nodes)\n",
        "  main_list.append(random_regular_3)\n",
        "  main_list.append(random_regular_20)\n",
        "  #-------------------------------------------------\n",
        "  # Create a random connected graph by generating a random spanning tree\n",
        "  random_connected_tree = nx.random_tree(num_nodes)\n",
        "  # Add additional edges to maintain connectivity\n",
        "  while not nx.is_connected(random_connected_tree):\n",
        "      node1 = random.choice(list(random_connected_tree.nodes()))\n",
        "      node2 = random.choice(list(random_connected_tree.nodes()))\n",
        "      if node1 != node2 and not random_connected_tree.has_edge(node1, node2):\n",
        "          random_connected_tree.add_edge(node1, node2)\n",
        "  main_list.append(random_connected_tree)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_cycle_graph(num_nodes):\n",
        "      if num_nodes < 3:\n",
        "          raise ValueError(\"Number of nodes must be at least 3 for a cycle.\")\n",
        "      cycle_graph = nx.cycle_graph(num_nodes)\n",
        "      # Connect the cycle to form a connected cycle graph\n",
        "      connected_cycle_graph = nx.connected_watts_strogatz_graph(num_nodes, 2, 0.1)\n",
        "      return connected_cycle_graph\n",
        "  random_cycle_graph = generate_random_connected_cycle_graph(num_nodes)\n",
        "  main_list.append(random_cycle_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_barabasi_albert_graph(num_nodes, m):\n",
        "      if num_nodes <= m:\n",
        "          raise ValueError(\"Number of nodes must be greater than m for a Barabási-Albert graph.\")\n",
        "      ba_graph = nx.barabasi_albert_graph(num_nodes, m)\n",
        "      while not nx.is_connected(ba_graph):\n",
        "          # Add edges to connect the graph\n",
        "          non_edges = list(nx.non_edges(ba_graph))\n",
        "          edge_to_add = non_edges[0]\n",
        "          ba_graph.add_edge(*edge_to_add)\n",
        "      return ba_graph\n",
        "  m_parameter = 2\n",
        "  random_connected_ba_graph = generate_random_connected_barabasi_albert_graph(num_nodes, m_parameter)\n",
        "  main_list.append(random_connected_ba_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_random_connected_erdos_renyi_graph(num_nodes, probability):\n",
        "      er_graph = nx.erdos_renyi_graph(num_nodes, probability)\n",
        "      while not nx.is_connected(er_graph):\n",
        "          # Add edges to connect the graph\n",
        "          non_edges = list(nx.non_edges(er_graph))\n",
        "          edge_to_add = non_edges[0]\n",
        "          er_graph.add_edge(*edge_to_add)\n",
        "      return er_graph\n",
        "  edge_probability = 0.1  # Adjust as needed\n",
        "  random_connected_er_graph = generate_random_connected_erdos_renyi_graph(num_nodes, edge_probability)\n",
        "  main_list.append(random_connected_er_graph)\n",
        "  #-------------------------------------------------\n",
        "  k = 2  # Each node is connected to k nearest neighbors\n",
        "  p = 0.3  # Probability of rewiring each edge\n",
        "  random_graph_ws = nx.watts_strogatz_graph(num_nodes, k, p)\n",
        "  main_list.append(random_graph_ws)\n",
        "  #-------------------------------------------------\n",
        "  k = 10  # Each node is connected to k nearest neighbors\n",
        "  p = 0.3  # Probability of rewiring each edge\n",
        "  random_graph_ws = nx.watts_strogatz_graph(num_nodes, k, p)\n",
        "  main_list.append(random_graph_ws)\n",
        "  #-------------------------------------------------\n",
        "\n",
        "  def generate_connected_random_geometric_graph(num_nodes, radius):\n",
        "      random_geo_graph = nx.random_geometric_graph(num_nodes, radius)\n",
        "      while not nx.is_connected(random_geo_graph):\n",
        "          # Connect the graph by adding edges\n",
        "          non_edges = list(nx.non_edges(random_geo_graph))\n",
        "          random_edge = random.choice(non_edges)\n",
        "          random_geo_graph.add_edge(*random_edge)\n",
        "      return random_geo_graph\n",
        "  radius = 0.1  # Adjust as needed\n",
        "  connected_random_geo_graph = generate_connected_random_geometric_graph(num_nodes, radius)\n",
        "  main_list.append(connected_random_geo_graph)\n",
        "  #-------------------------------------------------\n",
        "  def generate_connected_random_internet_graph(num_nodes, k, p):\n",
        "      internet_graph = nx.random_internet_as_graph(num_nodes)\n",
        "      while not nx.is_connected(internet_graph):\n",
        "          non_edges = list(nx.non_edges(internet_graph))\n",
        "          random_edge = non_edges[0]\n",
        "          internet_graph.add_edge(*random_edge)\n",
        "      undirected_internet_graph = internet_graph.to_undirected()\n",
        "      connected_random_internet_graph = nx.connected_watts_strogatz_graph(num_nodes, k, p)\n",
        "      return connected_random_internet_graph\n",
        "  k_parameter = 5\n",
        "  p_parameter = 0.5\n",
        "  connected_random_internet_graph = generate_connected_random_internet_graph(num_nodes, k_parameter, p_parameter)\n",
        "  main_list.append(connected_random_internet_graph)\n",
        "  #-------------------------------------------------\n",
        "  return main_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88tHVQnBfOCW",
        "outputId": "9e9b08e7-e91a-4268-9e1a-8175c1070e9a"
      },
      "outputs": [],
      "source": [
        "BigGraphs = create_Big_Graphs()\n",
        "main_list = create_main_graphs(5000)\n",
        "main_list2 = create_main_graphs(8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total dimensions for BigGraphs: 10000\n",
            "Total dimensions for main_list: 50000\n",
            "Total dimensions for main_list2: 80000\n"
          ]
        }
      ],
      "source": [
        "def total_dimensions(graphs):\n",
        "    return sum(len(graph.nodes()) for graph in graphs)\n",
        "\n",
        "# Calculate total dimensions for each list of graphs\n",
        "total_dims_BigGraphs = total_dimensions(BigGraphs)\n",
        "total_dims_main_list = total_dimensions(main_list)\n",
        "total_dims_main_list2 = total_dimensions(main_list2)\n",
        "\n",
        "print(\"Total dimensions for BigGraphs: {}\".format(total_dims_BigGraphs))\n",
        "print(\"Total dimensions for main_list: {}\".format(total_dims_main_list))\n",
        "print(\"Total dimensions for main_list2: {}\".format(total_dims_main_list2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uZC4_6jAjKJ7"
      },
      "outputs": [],
      "source": [
        "# GCN yayılım fonksiyonu.\n",
        "def gcn_propagate(adj_matrix, node_embeddings):\n",
        "    # Laplacian Normalization\n",
        "    degrees = adj_matrix.sum(axis=1)\n",
        "    degree_matrix = np.diag(degrees)\n",
        "    laplacian = degree_matrix - adj_matrix\n",
        "    norm_laplacian = np.linalg.pinv(degree_matrix) @ laplacian\n",
        "    return np.dot(norm_laplacian, node_embeddings)\n",
        "\n",
        "# GCN ile gömme vektörleri oluşturur.\n",
        "def generate_embeddings(graphs, target_dim=47616, num_iterations=10):\n",
        "    embeddings = []\n",
        "    for graph in graphs:\n",
        "        adj_matrix = nx.to_numpy_array(graph)\n",
        "        initial_dim = adj_matrix.shape[0]\n",
        "        node_embeddings = np.random.randn(initial_dim, initial_dim)\n",
        "\n",
        "        for _ in range(num_iterations):\n",
        "            node_embeddings = gcn_propagate(adj_matrix, node_embeddings)\n",
        "\n",
        "        graph_embedding = np.mean(node_embeddings, axis=0)\n",
        "        padding_length = max(0, target_dim - graph_embedding.shape[0])\n",
        "        embeddings.append(np.pad(graph_embedding, (0, padding_length), 'constant'))\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "# Önceden eğitilmiş bir sınıflandırıcı modeli yükler.\n",
        "try:\n",
        "    with open('classifier.pkl', 'rb') as file:\n",
        "        loaded_model = pickle.load(file)\n",
        "except FileNotFoundError:\n",
        "    print(\"Model dosyası bulunamadı.\")\n",
        "    loaded_model = None\n",
        "except Exception as e:\n",
        "    print(f\"Model yüklenirken bir hata oluştu: {e}\")\n",
        "    loaded_model = None\n",
        "\n",
        "# Sayaç tut eğer 30 dakikayı geçerse timeout ver.\n",
        "import time\n",
        "if loaded_model:\n",
        "    for graphs, name in [(BigGraphs, \"BigGraphs\"), (main_list, \"main_list\"), (main_list2, \"main_list2\")]:\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            embeddings = generate_embeddings(graphs)\n",
        "            elapsed_time = time.time() - start_time\n",
        "\n",
        "            print(f\"Elapsed time: {elapsed_time} seconds\\n\")\n",
        "\n",
        "            if elapsed_time > 1800:\n",
        "                print(\"Timeout!\")\n",
        "\n",
        "            # Tahmin olasılıklarını hesapla\n",
        "            probabilities = loaded_model.predict_proba(embeddings)\n",
        "            # Her tahmin için yüzdelik değerleri hesapla\n",
        "            percentage_predictions = np.round(probabilities * 100, 2)  # Yüzdelik değerleri yuvarla\n",
        "            print(f\"==== {name} ==== \\nPercentage of predictions: \\n{percentage_predictions}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"{name} için tahmin yapılırken hata oluştu: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
